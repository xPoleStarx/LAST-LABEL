{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run multilabel_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run test.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weights_multilabel(y, num_classes=10):\n",
    "    # Ensure y is a 2D array\n",
    "    if y.ndim == 1:\n",
    "        y = y.reshape(-1, 1)\n",
    "    \n",
    "    # Count occurrences of each class\n",
    "    class_counts = np.sum(y, axis=0)\n",
    "    \n",
    "    # Compute weights\n",
    "    weights = np.zeros(num_classes)\n",
    "    n_samples = len(y)\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        if class_counts[i] > 0:\n",
    "            weights[i] = (n_samples / (num_classes * class_counts[i]))\n",
    "        else:\n",
    "            weights[i] = 1.0  # or any other strategy for classes with no samples\n",
    "    \n",
    "    # Normalize weights\n",
    "    weights = weights / np.sum(weights) * num_classes\n",
    "    \n",
    "    # Create a dictionary mapping class labels to weights\n",
    "    class_weight_dict = {i: weight for i, weight in enumerate(weights)}\n",
    "    \n",
    "    class_weights = torch.FloatTensor(list(class_weight_dict.values())).cuda()\n",
    "\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_weights_multilabel(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-6, 1e-1)\n",
    "    hidden_dim = trial.suggest_categorical('hidden_dim', [32, 64, 128, 256, 512, 1024])\n",
    "    epochs = trial.suggest_categorical('epochs', [50, 100, 150, 200, 250])\n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-5, 1e-2)\n",
    "    beta1 = trial.suggest_uniform('beta1', 0.5, 0.9999)\n",
    "    beta2 = trial.suggest_uniform('beta2', 0.9, 0.9999)\n",
    "    dropout = trial.suggest_uniform('dropout', 0.0, 0.5)\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = num_classes\n",
    "\n",
    "    model = CNNModel(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, dropout_prob=dropout).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2), weight_decay=weight_decay)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights)\n",
    "\n",
    "    model = training_model(model, optimizer, criterion, train_loader, test_loader, epochs, device)\n",
    "    accuracy, precision, recall, f1 = test_model(model, test_loader, device)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.load_study(study_name='cnn', storage='sqlite:///multilabelclassification.db')\n",
    "# study.optimize(objective, n_trials=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_number = 100\n",
    "trial = study.trials[trial_number]\n",
    "\n",
    "# Extract the parameters\n",
    "params = trial.params\n",
    "\n",
    "# Save the parameters as a JSON file\n",
    "with open(f'trial_{trial_number}_params.json', 'w') as f:\n",
    "    json.dump(params, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
